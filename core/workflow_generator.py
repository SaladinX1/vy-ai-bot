# üìÅ Dossier : core/workflow_generator.py
# üìÅ core/workflow_generator.py
import openai
import os
import json
from llm.llm_interface import query_mistral

from core import memory

openai.api_key = os.getenv("MISTRAL_API_KEY")
openai.api_base = os.getenv("OPENAI_API_BASE")


def map_llm_output_to_internal_tasks(llm_tasks):
    mapped = []
    for t in llm_tasks:
        label = t.get("task", "").lower()

        if "niche" in label or "march√©" in label:
            mapped.append({"task": "niche_analysis", "input": {"query": t["params"].get("query", "")}})
        elif "copy" in label or "texte" in label:
            mapped.append({"task": "copywriting", "input": {"content": t["params"].get("content", "")}})
        elif "youtube" in label:
            mapped.append({"task": "youtube", "input": t["params"]})
        elif "tiktok" in label:
            mapped.append({"task": "tiktok", "input": t["params"]})
        else:
            print(f"[IGNOR√â] T√¢che non mapp√©e : {label}")
            continue

    # Ajoute la t√¢che "lesson" √† la fin pour le suivi
    mapped.append({
        "task": "lesson",
        "input": {
            "goal": "auto",
            "score": 0.0,
            "result": "pending"
        }
    })

    return mapped


def generate_workflow(goal: str):
    past_lessons = memory.get_recent_lessons(limit=3)
    formatted_lessons = "\n".join([f"- {lesson['lesson']}" for lesson in past_lessons]) if past_lessons else "Aucune le√ßon."

    prompt = f"""
Tu es un agent sp√©cialis√© dans la cr√©ation de workflows m√©tiers.
Objectif : "{goal}"

Voici quelques √©checs r√©cents √† √©viter :
{formatted_lessons}

G√©n√®re un plan d'action structur√© en 5 √† 10 √©tapes maximum.
Retourne le r√©sultat au format JSON, sous forme d‚Äôune liste contenant :
- "task": nom de la t√¢che √† ex√©cuter
- "tool": l‚Äôoutil √† utiliser (ex: 'browser', 'code_executor', 'file_writer', etc.)
- "params": dictionnaire des param√®tres n√©cessaires

Exemple :
[
  {{
    "task": "Faire une recherche Google sur le march√© cible",
    "tool": "browser",
    "params": {{"query": "√©tude de march√© dropshipping France 2024"}}
  }},
  ...
]
    """.strip()

    try:
        response = query_mistral(prompt, system_prompt="Tu es un agent g√©n√©rateur de plans d'action automatis√©s.")
        workflow = json.loads(response)
        mapped_workflow = map_llm_output_to_internal_tasks(workflow)
        return mapped_workflow
    except Exception as e:
        print(f"[ERREUR] √âchec de g√©n√©ration de workflow : {e}")
        return []
